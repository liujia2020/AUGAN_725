import argparse
import logging
import os
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import scipy.io as sio
import time
import sys
import os
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from cubdl.example_picmus_torch import load_datasets,create_network,mk_img,dispaly_img
from options.train_options import TrainOptions
from models import create_model
from data_process import load_dataset, test_image, load_dataset_multi  # ä½¿ç”¨åŸå§‹ç‰ˆæœ¬é¿å…CUDAé—®é¢˜
from utils.util import diagnose_network
from models.network import UnetGenerator
import math
from tqdm import tqdm
from torch.utils.data import DataLoader,Dataset,TensorDataset
from utils.metrics import image_evaluation

def makedir(opt):
    train_base = './images/' + opt.name + '/train'
    test_base = './images/' + opt.name + '/test'
    if not os.path.exists(train_base):
        os.makedirs(train_base)
    if not os.path.exists(test_base):
        os.makedirs(test_base)
    loss_path = './images/' + opt.name + '/train/loss.png'
    return loss_path

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨è®­ç»ƒè„šæœ¬...")
    
    # Initial setting and corresponding parameters
    plane_wave_data = load_datasets("simulation", "resolution_distorsion", "iq")
    das, iqdata, xlims, zlims = create_network(plane_wave_data, [1])

    opt = TrainOptions().parse()
    
    # æ£€æŸ¥è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

    # Load the model
    model = create_model(opt)
    model.setup(opt)
    print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ°è®¾å¤‡: {model.device}")
    
    total_iters = 0
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    loss_path = makedir(opt)

    print("ğŸ“‚ å¼€å§‹åŠ è½½æ•°æ®é›†...")
    start_load_time = time.time()
    
    # ä½¿ç”¨åŸå§‹æ•°æ®åŠ è½½ï¼ˆæ›´ç¨³å®šï¼‰
    # img_dataset = load_dataset(opt, opt.phase, 0)
    
    img_dataset = load_dataset_multi(opt, opt.phase, 0)  # ğŸ¯ ä½¿ç”¨å¤šæ•°æ®é›†ç‰ˆæœ¬
    print("æ•°æ®é›†æ ·æœ¬æ€»æ•°ï¼š", len(img_dataset))
    dataset_len = img_dataset.len
    
    load_time = time.time() - start_load_time
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼Œç”¨æ—¶: {load_time:.2f}ç§’")
    print(f"ğŸ“Š æ•°æ®é›†å¤§å°: {dataset_len}")
    
    # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šDataLoaderé…ç½®
    available_workers = os.cpu_count() if os.cpu_count() else 4
    num_workers = min(8, available_workers)  # å¢åŠ åˆ°8ä¸ªworker
    
    print(f"âš™ï¸ ç³»ç»Ÿæœ‰ {available_workers} ä¸ªCPUæ ¸å¿ƒï¼Œä½¿ç”¨ {num_workers} ä¸ªworker")
    
    train_loader = DataLoader(
        dataset=img_dataset, 
        num_workers=num_workers,               # ğŸ”¥ å…³é”®ï¼š8ä¸ªå¹¶è¡Œworker
        batch_size=1,                          # ä¿æŒbatch_size=1é¿å…å†…å­˜é—®é¢˜
        shuffle=True,
        pin_memory=torch.cuda.is_available(),  # ğŸ”¥ å…³é”®ï¼šå†…å­˜å›ºå®š
        prefetch_factor=8,                     # ğŸ”¥ å…³é”®ï¼šå¤§å¹…å¢åŠ é¢„å–
        persistent_workers=True,               # ğŸ”¥ å…³é”®ï¼šä¿æŒworkerè¿›ç¨‹
        drop_last=False
    )
    
    print(f"ğŸ”¥ é«˜æ€§èƒ½DataLoaderé…ç½®:")
    print(f"   - Workers: {num_workers}")
    print(f"   - Pin Memory: {torch.cuda.is_available()}")
    print(f"   - Prefetch Factor: 8")
    print(f"   - Persistent Workers: True")
    
    # åˆå§‹åŒ–æŸå¤±æ•°ç»„
    lossG = np.zeros(opt.n_epochs + opt.niter_decay)
    lossD = np.zeros(opt.n_epochs + opt.niter_decay)

    # Image evaluation
    img_eva = image_evaluation()

    print("ğŸ“ å¼€å§‹è®­ç»ƒ...")
    
    # æ€§èƒ½ç»Ÿè®¡
    batch_times = []
    gpu_utilizations = []
    
    # Training process
    for epoch in range(opt.epoch_count, opt.n_epochs + opt.niter_decay + 1):
        epoch_start_time = time.time()
        epoch_iter = 0
        
        # è¯¦ç»†çš„è¿›åº¦æ¡
        train_bar = tqdm(
            train_loader, 
            desc=f'Epoch {epoch}/{opt.n_epochs + opt.niter_decay}',
            ncols=140,
            unit='batch',
            smoothing=0.1
        )
        
        epoch_batch_times = []
        
        for batch_idx, batch_data in enumerate(train_bar):
            batch_start = time.time()
            
            # ä»å­—å…¸ä¸­è·å–æ•°æ®
            data = batch_data['A']
            target = batch_data['B']
            
            # è®­ç»ƒ
            model.set_input(data, target)
            model.optimize_parameters()
            
            epoch_iter += opt.batch_size
            batch_time = time.time() - batch_start
            epoch_batch_times.append(batch_time)
            
            # å®æ—¶æ€§èƒ½ç›‘æ§
            if batch_idx % 20 == 0:
                try:
                    performance_info = {
                        'Batch_ms': f"{batch_time*1000:.0f}ms"
                    }
                    
                    # GPUä¿¡æ¯
                    if torch.cuda.is_available():
                        gpu_memory = torch.cuda.memory_allocated() / 1e9
                        gpu_cached = torch.cuda.memory_reserved() / 1e9
                        performance_info.update({
                            'GPU_mem': f"{gpu_memory:.1f}GB",
                            'GPU_cache': f"{gpu_cached:.1f}GB"
                        })
                    
                    # æŸå¤±ä¿¡æ¯
                    try:
                        if hasattr(model, 'loss_G_GAN') and hasattr(model, 'loss_D_real'):
                            performance_info.update({
                                'G_loss': f"{float(model.loss_G_GAN):.3f}",
                                'D_loss': f"{float(model.loss_D_real):.3f}"
                            })
                    except:
                        pass
                    
                    train_bar.set_postfix(performance_info)
                    
                except ImportError:
                    # å¦‚æœæ¨¡å—ä¸å¯ç”¨ï¼Œæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                    train_bar.set_postfix({
                        'Time': f"{batch_time*1000:.0f}ms",
                        'Status': 'Training...'
                    })
                except Exception as e:
                    # ä»»ä½•å…¶ä»–é”™è¯¯ï¼Œä¿æŒç®€å•æ˜¾ç¤º
                    train_bar.set_postfix({'Status': 'Running...'})
        
        # Epochç»Ÿè®¡
        epoch_time = time.time() - epoch_start_time
        avg_batch_time = np.mean(epoch_batch_times) if epoch_batch_times else 0
        batches_per_sec = len(train_loader) / epoch_time if epoch_time > 0 else 0
        
        print(f"\nğŸ“ˆ Epoch {epoch} å®Œæˆ:")
        print(f"   â±ï¸  æ€»æ—¶é—´: {epoch_time:.1f}ç§’")
        print(f"   ğŸ“Š å¹³å‡æ‰¹æ¬¡æ—¶é—´: {avg_batch_time*1000:.1f}ms")
        print(f"   ğŸš€ å¤„ç†é€Ÿåº¦: {batches_per_sec:.1f} batches/ç§’")
        
        # ä¿å­˜æ€§èƒ½æ•°æ®
        batch_times.extend(epoch_batch_times)
        
        # æŸå¤±è®°å½•
        try:
            if hasattr(model, 'loss_G_GAN'):
                lossG[epoch-1] = float(model.loss_G_GAN)
            if hasattr(model, 'loss_D_real'):
                lossD[epoch-1] = float(model.loss_D_real)
        except:
            pass
        
        # å®šæœŸä¿å­˜å’Œæ¸…ç†
        if epoch % 10 == 0:
            model.save_networks(epoch)
            print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜ - Epoch {epoch}")
            
            # GPUå†…å­˜æ¸…ç†
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                current_memory = torch.cuda.memory_allocated() / 1e9
                print(f"ğŸ§¹ GPUç¼“å­˜å·²æ¸…ç†ï¼Œå½“å‰ä½¿ç”¨: {current_memory:.1f}GB")
        
        # æ›´æ–°å­¦ä¹ ç‡
        model.update_learning_rate()
        
        print("-" * 60)

    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    model.save_networks('latest')
    print("ğŸ’¾ æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜")
    
    # æ€§èƒ½æŠ¥å‘Š
    if batch_times:
        avg_batch_time = np.mean(batch_times) * 1000
        min_batch_time = np.min(batch_times) * 1000
        max_batch_time = np.max(batch_times) * 1000
        
        print(f"\nğŸ“Š æ€§èƒ½æŠ¥å‘Š:")
        print(f"   å¹³å‡æ‰¹æ¬¡æ—¶é—´: {avg_batch_time:.1f}ms")
        print(f"   æœ€å¿«æ‰¹æ¬¡æ—¶é—´: {min_batch_time:.1f}ms")
        print(f"   æœ€æ…¢æ‰¹æ¬¡æ—¶é—´: {max_batch_time:.1f}ms")
        print(f"   æ€§èƒ½ä¼˜åŒ–æ•ˆæœ: å¤šè¿›ç¨‹æ•°æ®åŠ è½½ + å†…å­˜å›ºå®š + é¢„å–ç¼“å†²")
        
        if avg_batch_time < 200:
            print("âœ… æ€§èƒ½ä¼˜ç§€ï¼æ‰¹æ¬¡å¤„ç†æ—¶é—´ < 200ms")
        elif avg_batch_time < 500:
            print("âš ï¸  æ€§èƒ½è‰¯å¥½ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´")
        else:
            print("âŒ æ€§èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")