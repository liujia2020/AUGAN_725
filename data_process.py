#!/usr/bin/env python3
"""
AUGAN æ•°æ®å¤„ç†æ¨¡å— - è¯¦ç»†æ³¨é‡Šç‰ˆ
data_process_annotated.py - å¤„ç†PICMUSè¶…å£°æ•°æ®é›†ï¼Œç”Ÿæˆè®­ç»ƒæ‰€éœ€çš„å›¾åƒå¯¹

ä¸»è¦åŠŸèƒ½:
1. åŠ è½½PICMUS HDF5æ•°æ®é›†
2. æ‰§è¡ŒDAS (Delay-and-Sum) é‡å»ºç®—æ³•
3. ç”Ÿæˆå•è§’åº¦å’Œå¤šè§’åº¦è¶…å£°å›¾åƒå¯¹
4. æ•°æ®é¢„å¤„ç†å’Œå½’ä¸€åŒ–
5. åˆ›å»ºPyTorchæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨

æ•°æ®æµç¨‹:
PICMUSæ•°æ® â†’ DASé‡å»º â†’ å›¾åƒå¯¹ç”Ÿæˆ â†’ æ•°æ®é›†å°è£… â†’ è®­ç»ƒ/æµ‹è¯•ä½¿ç”¨
"""

import torch
import logging
import numpy as np
import scipy.io as sio
from torch.utils.data import DataLoader, Dataset, TensorDataset
from cubdl.example_picmus_torch import load_datasets, create_network, mk_img, dispaly_img


class AUGANDataset(Dataset):
    """
    AUGANä¸“ç”¨æ•°æ®é›†ç±»
    
    åŠŸèƒ½:
        å°è£…å¤„ç†åçš„è¶…å£°å›¾åƒæ•°æ®ï¼Œæä¾›PyTorchæ ‡å‡†æ•°æ®é›†æ¥å£
    
    æ•°æ®ç»“æ„:
        - A: è¾“å…¥å›¾åƒï¼ˆå•è§’åº¦DASé‡å»ºï¼Œä½è´¨é‡ï¼‰
        - B: ç›®æ ‡å›¾åƒï¼ˆå¤šè§’åº¦å¤åˆé‡å»ºï¼Œé«˜è´¨é‡ï¼‰
    """
    
    def __init__(self, input_images, target_images, phase='train'):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        å‚æ•°:
            input_images: è¾“å…¥å›¾åƒåˆ—è¡¨ï¼ˆå•è§’åº¦ï¼‰
            target_images: ç›®æ ‡å›¾åƒåˆ—è¡¨ï¼ˆå¤šè§’åº¦ï¼‰
            phase: æ•°æ®é›†é˜¶æ®µ ('train', 'test', 'val')
        """
        self.input_images = input_images
        self.target_images = target_images
        self.phase = phase
        self.len = len(input_images)
        
        print(f"ğŸ“Š åˆ›å»º{phase}æ•°æ®é›†: {self.len}ä¸ªæ ·æœ¬")
    
    def __len__(self):
        """è¿”å›æ•°æ®é›†å¤§å°"""
        return self.len
    
    def __getitem__(self, index):
        """
        è·å–å•ä¸ªæ•°æ®æ ·æœ¬
        
        å‚æ•°:
            index: æ•°æ®ç´¢å¼•
        
        è¿”å›:
            data: åŒ…å«A(è¾“å…¥)å’ŒB(ç›®æ ‡)çš„å­—å…¸
        """
        # è·å–å¯¹åº”çš„è¾“å…¥å’Œç›®æ ‡å›¾åƒ
        input_img = self.input_images[index]
        target_img = self.target_images[index]
        
        # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32
        if isinstance(input_img, np.ndarray):
            input_img = torch.from_numpy(input_img).float()
        if isinstance(target_img, np.ndarray):
            target_img = torch.from_numpy(target_img).float()
        
        # ç¡®ä¿ç»´åº¦æ­£ç¡® [C, H, W]
        if len(input_img.shape) == 2:
            input_img = input_img.unsqueeze(0)  # æ·»åŠ é€šé“ç»´åº¦
        if len(target_img.shape) == 2:
            target_img = target_img.unsqueeze(0)
        
        return {
            'A': input_img,      # è¾“å…¥å›¾åƒï¼ˆå•è§’åº¦ï¼‰
            'B': target_img,     # ç›®æ ‡å›¾åƒï¼ˆå¤šè§’åº¦ï¼‰
            'A_paths': f'input_{index}',    # è¾“å…¥è·¯å¾„ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            'B_paths': f'target_{index}'    # ç›®æ ‡è·¯å¾„ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        }
    
    def get_item(self, index):
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼Œä¸åŸæœ‰ä»£ç æ¥å£ä¿æŒä¸€è‡´
        """
        return self.__getitem__(index)


def test_image(data, data1, target, xlims, zlims, i, phase, name):
    """
    å¯è§†åŒ–å‡½æ•°ï¼šæ˜¾ç¤ºåŸå§‹å›¾åƒã€é‡å»ºå›¾åƒå’Œç›®æ ‡å›¾åƒçš„å¯¹æ¯”
    
    å‚æ•°è¯´æ˜:
        data (tensor): è¾“å…¥å›¾åƒ (å•è§’åº¦DASå›¾åƒ)
        data1 (tensor): ç”Ÿæˆå™¨é‡å»ºçš„å›¾åƒ 
        target (tensor): ç›®æ ‡å›¾åƒ (å¤åˆè§’åº¦é«˜è´¨é‡å›¾åƒ)
        xlims, zlims: æ˜¾ç¤ºçš„åæ ‡èŒƒå›´
        i: å›¾åƒç´¢å¼•
        phase: è®­ç»ƒé˜¶æ®µ ('train' æˆ– 'test')
        name: å®éªŒåç§°
    
    æ³¨æ„: ä¿æŒåŸæœ‰çš„å‚æ•°åä»¥ç¡®ä¿å‘åå…¼å®¹æ€§
    """
    # é‡å‘½åå‚æ•°ä»¥æé«˜å†…éƒ¨ä»£ç å¯è¯»æ€§
    input_image = data
    generated_image = data1
    target_image = target
    
    # å°†tensorè½¬ä¸ºnumpyï¼Œä¾¿äºåç»­å¤„ç†å’Œæ˜¾ç¤º
    input_image_np = input_image.detach().cpu().numpy()      # è¾“å…¥å›¾åƒ (ä½è´¨é‡å•è§’åº¦)
    input_image_np = np.squeeze(input_image_np)              # ç§»é™¤å¤§å°ä¸º1çš„ç»´åº¦
    input_image_np -= np.max(input_image_np)                 # æ ‡å‡†åŒ–ï¼šå‡å»æœ€å¤§å€¼ (dBè¡¨ç¤ºï¼Œä½¿æœ€å¤§å€¼ä¸º0dB)

    generated_image_np = generated_image.detach().cpu().numpy()    # ç”Ÿæˆå™¨è¾“å‡ºå›¾åƒ (å¢å¼ºå)
    generated_image_np = np.squeeze(generated_image_np)
    generated_image_np -= np.max(generated_image_np)               # åŒæ ·æ ‡å‡†åŒ–

    target_image_np = target_image.detach().cpu().numpy()   # ç›®æ ‡å›¾åƒ (é«˜è´¨é‡å¤åˆè§’åº¦)
    target_image_np = np.squeeze(target_image_np)
    target_image_np -= np.max(target_image_np)               # åŒæ ·æ ‡å‡†åŒ–

    # è°ƒç”¨ä¸“é—¨çš„è¶…å£°å›¾åƒæ˜¾ç¤ºå‡½æ•°ï¼Œæ˜¾ç¤ºä¸‰å›¾å¯¹æ¯”
    # [1] è¡¨ç¤ºæ˜¾ç¤ºçš„è§’åº¦åˆ—è¡¨
    dispaly_img(input_image_np, generated_image_np, target_image_np, xlims, zlims, [1], i, phase, name)


def create_das_reconstructions(plane_wave_data, single_angle=[1], multi_angles=None):
    """
    åˆ›å»ºDASé‡å»ºå›¾åƒ
    
    å‚æ•°:
        plane_wave_data: PICMUSå¹³é¢æ³¢æ•°æ®
        single_angle: å•è§’åº¦åˆ—è¡¨ï¼ˆä½œä¸ºè¾“å…¥ï¼‰
        multi_angles: å¤šè§’åº¦åˆ—è¡¨ï¼ˆä½œä¸ºç›®æ ‡ï¼ŒNoneæ—¶ä½¿ç”¨æ‰€æœ‰è§’åº¦ï¼‰
    
    è¿”å›:
        single_images: å•è§’åº¦é‡å»ºå›¾åƒåˆ—è¡¨
        multi_images: å¤šè§’åº¦é‡å»ºå›¾åƒåˆ—è¡¨
        das, iqdata, xlims, zlims: DASç›¸å…³å‚æ•°
    
    DASåŸç†:
        Delay-and-Sumç®—æ³•æ˜¯è¶…å£°æˆåƒçš„æ ¸å¿ƒé‡å»ºæ–¹æ³•
        - å•è§’åº¦ï¼šä½¿ç”¨å•ä¸€å‘å°„è§’åº¦ï¼Œå›¾åƒè´¨é‡è¾ƒä½ä½†é€Ÿåº¦å¿«
        - å¤šè§’åº¦ï¼šä½¿ç”¨å¤šä¸ªè§’åº¦å¤åˆï¼Œå›¾åƒè´¨é‡é«˜ä½†è®¡ç®—é‡å¤§
    """
    print("ğŸ”¬ æ‰§è¡ŒDASé‡å»ºç®—æ³•...")
    
    # åˆ›å»ºå•è§’åº¦DASç½‘ç»œï¼ˆè¾“å…¥å›¾åƒï¼‰
    print(f"ğŸ“¡ å•è§’åº¦é‡å»º: è§’åº¦ {single_angle}")
    das_single, iqdata, xlims, zlims = create_network(plane_wave_data, single_angle)
    
    # åˆ›å»ºå¤šè§’åº¦DASç½‘ç»œï¼ˆç›®æ ‡å›¾åƒï¼‰
    if multi_angles is None:
        # ä½¿ç”¨æ‰€æœ‰å¯ç”¨è§’åº¦ï¼ˆé€šå¸¸æ˜¯75ä¸ªè§’åº¦ï¼š-37Â°åˆ°37Â°ï¼‰
        multi_angles = list(range(len(plane_wave_data.angles)))
        print(f"ğŸ“¡ å¤šè§’åº¦é‡å»º: ä½¿ç”¨å…¨éƒ¨ {len(multi_angles)} ä¸ªè§’åº¦")
    else:
        print(f"ğŸ“¡ å¤šè§’åº¦é‡å»º: è§’åº¦ {multi_angles}")
    
    das_multi, _, _, _ = create_network(plane_wave_data, multi_angles)
    
    # æ‰§è¡Œé‡å»º
    print("âš™ï¸  æ‰§è¡Œå›¾åƒé‡å»º...")
    single_images = []
    multi_images = []
    
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ ¹æ®å…·ä½“çš„PICMUSæ•°æ®ç»“æ„æ¥å¤„ç†
    # å‡è®¾æˆ‘ä»¬æœ‰Nä¸ªè¶…å£°å¸§éœ€è¦å¤„ç†
    num_frames = getattr(plane_wave_data, 'nb_frames', 100)  # é»˜è®¤100å¸§
    
    # ç®€åŒ–å¤„ç†ï¼šåªç”Ÿæˆä¸€å¼ å›¾åƒç”¨äºæ¼”ç¤º
    try:
        # å•è§’åº¦é‡å»ºï¼ˆè¾“å…¥ï¼‰
        single_img = mk_img(das_single, iqdata)
        single_images.append(single_img)
        
        # å¤šè§’åº¦é‡å»ºï¼ˆç›®æ ‡ï¼‰
        multi_img = mk_img(das_multi, iqdata)
        multi_images.append(multi_img)
        
        print(f"âœ… é‡å»ºå®Œæˆ: 1 å¯¹å›¾åƒ")
        
    except Exception as e:
        print(f"âš ï¸  å›¾åƒé‡å»ºå¤±è´¥: {e}")
        return [], [], das_single, iqdata, xlims, zlims
    
    return single_images, multi_images, das_single, iqdata, xlims, zlims


def preprocess_images(images, normalize=True, log_compress=True, target_size=None):
    """
    å›¾åƒé¢„å¤„ç†
    
    å‚æ•°:
        images: å›¾åƒåˆ—è¡¨
        normalize: æ˜¯å¦å½’ä¸€åŒ–åˆ°[0,1]
        log_compress: æ˜¯å¦åº”ç”¨å¯¹æ•°å‹ç¼©
        target_size: ç›®æ ‡å›¾åƒå°ºå¯¸ (H, W)
    
    è¿”å›:
        processed_images: å¤„ç†åçš„å›¾åƒåˆ—è¡¨
    
    é¢„å¤„ç†æ­¥éª¤:
        1. å¯¹æ•°å‹ç¼©ï¼ˆæ¨¡æ‹Ÿè¶…å£°æˆåƒçš„æ˜¾ç¤ºæ–¹å¼ï¼‰
        2. å°ºå¯¸è°ƒæ•´åˆ°256x256
        3. å½’ä¸€åŒ–ï¼ˆä¾¿äºç¥ç»ç½‘ç»œè®­ç»ƒï¼‰
        4. æ•°æ®ç±»å‹è½¬æ¢
    """
    import cv2
    print("ğŸ”§ æ‰§è¡Œå›¾åƒé¢„å¤„ç†...")
    processed_images = []
    
    for i, img in enumerate(images):
        try:
            # ç¡®ä¿ä¸ºnumpyæ•°ç»„
            if torch.is_tensor(img):
                img = img.detach().cpu().numpy()
            
            print(f"ğŸ“ åŸå§‹å›¾åƒ{i}å°ºå¯¸: {img.shape}")
            
            # å¯¹æ•°å‹ç¼©ï¼ˆè¶…å£°æˆåƒæ ‡å‡†å¤„ç†ï¼‰
            if log_compress:
                # é¿å…log(0)ï¼Œæ·»åŠ å°å¸¸æ•°
                img = np.log10(np.abs(img) + 1e-10)
            
            # å½’ä¸€åŒ–åˆ°[0, 1]
            if normalize:
                img_min = np.min(img)
                img_max = np.max(img)
                if img_max > img_min:
                    img = (img - img_min) / (img_max - img_min)
                else:
                    img = np.zeros_like(img)
            
            # æ™ºèƒ½å°ºå¯¸å¤„ç†ï¼špaddingåˆ°512x512è€Œä¸æ˜¯resizeï¼Œä¿æŒæ•°æ®å®Œæ•´æ€§
            if img.shape[0] < 512 or img.shape[1] < 512:
                # è®¡ç®—padding
                pad_h = max(0, 512 - img.shape[0])
                pad_w = max(0, 512 - img.shape[1])
                # å¯¹ç§°padding
                pad_top = pad_h // 2
                pad_bottom = pad_h - pad_top
                pad_left = pad_w // 2
                pad_right = pad_w - pad_left
                
                original_shape = img.shape
                img = np.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant', constant_values=0)
                print(f"ğŸ”„ å›¾åƒ{i} padding: {original_shape[0]}x{original_shape[1]} -> {img.shape[0]}x{img.shape[1]} (ä¿æŒæ•°æ®å®Œæ•´æ€§)")
            else:
                print(f"âœ… ä¿æŒåŸå§‹å°ºå¯¸: {img.shape}")
            
            # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32
            img = img.astype(np.float32)
            
            processed_images.append(img)
            
        except Exception as e:
            print(f"âš ï¸  å›¾åƒ {i} é¢„å¤„ç†å¤±è´¥: {e}")
            continue
    
    if target_size:
        print(f"âœ… é¢„å¤„ç†å®Œæˆ: {len(processed_images)} å¼ å›¾åƒï¼Œç›®æ ‡å°ºå¯¸: {target_size}")
    else:
        print(f"âœ… é¢„å¤„ç†å®Œæˆ: {len(processed_images)} å¼ å›¾åƒï¼Œä¿æŒåŸå§‹å°ºå¯¸")
    return processed_images


def split_dataset(input_images, target_images, train_ratio=0.8, val_ratio=0.1):
    """
    æ•°æ®é›†åˆ’åˆ†
    
    å‚æ•°:
        input_images: è¾“å…¥å›¾åƒåˆ—è¡¨
        target_images: ç›®æ ‡å›¾åƒåˆ—è¡¨
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
        val_ratio: éªŒè¯é›†æ¯”ä¾‹ï¼ˆå‰©ä½™ä¸ºæµ‹è¯•é›†ï¼‰
    
    è¿”å›:
        splits: åŒ…å«train/val/teståˆ’åˆ†çš„å­—å…¸
    """
    print("ğŸ“Š åˆ’åˆ†æ•°æ®é›†...")
    
    total_samples = len(input_images)
    
    # å¦‚æœæ ·æœ¬å¤ªå°‘ï¼Œè°ƒæ•´åˆ’åˆ†ç­–ç•¥
    if total_samples <= 3:
        # æ ·æœ¬å¤ªå°‘æ—¶ï¼Œå…¨éƒ¨ç”¨ä½œè®­ç»ƒï¼Œå¤åˆ¶æ•°æ®å¢åŠ æ ·æœ¬æ•°
        print(f"âš ï¸  æ ·æœ¬æ•°é‡è¿‡å°‘({total_samples})ï¼Œå¤åˆ¶æ•°æ®ä»¥å¢åŠ è®­ç»ƒæ ·æœ¬")
        # å¤åˆ¶æ•°æ®10æ¬¡
        multiplied_input = input_images * 10
        multiplied_target = target_images * 10
        train_size = len(multiplied_input)
        val_size = 0
        test_size = total_samples  # åŸå§‹æ•°æ®ç”¨ä½œæµ‹è¯•
        
        train_indices = list(range(train_size))
        val_indices = []
        test_indices = list(range(total_samples))
        
        splits = {
            'train': {
                'input': multiplied_input,
                'target': multiplied_target
            },
            'val': {
                'input': [],
                'target': []
            },
            'test': {
                'input': input_images,
                'target': target_images
            }
        }
    else:
        # æ­£å¸¸åˆ’åˆ†
        train_size = max(1, int(total_samples * train_ratio))
        val_size = max(0, int(total_samples * val_ratio))
        test_size = total_samples - train_size - val_size
        
        # éšæœºæ‰“ä¹±ç´¢å¼•
        indices = np.random.permutation(total_samples)
        
        train_indices = indices[:train_size]
        val_indices = indices[train_size:train_size + val_size]
        test_indices = indices[train_size + val_size:]
        
        splits = {
            'train': {
                'input': [input_images[i] for i in train_indices],
                'target': [target_images[i] for i in train_indices]
            },
            'val': {
                'input': [input_images[i] for i in val_indices],
                'target': [target_images[i] for i in val_indices]
            },
            'test': {
                'input': [input_images[i] for i in test_indices],
                'target': [target_images[i] for i in test_indices]
            }
        }
    
    return splits


def load_dataset(opt, phase, dataset_index=0):
    """
    åŠ è½½æ•°æ®é›†ï¼ˆå…¼å®¹åŸæ¥å£ï¼‰
    
    å‚æ•°:
        opt: è®­ç»ƒ/æµ‹è¯•é€‰é¡¹
        phase: æ•°æ®é›†é˜¶æ®µ ('train', 'test', 'val')
        dataset_index: æ•°æ®é›†ç´¢å¼•ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰
    
    è¿”å›:
        dataset: AUGANæ•°æ®é›†å¯¹è±¡
    
    åŠŸèƒ½:
        1. åŠ è½½PICMUSæ•°æ®
        2. æ‰§è¡ŒDASé‡å»º
        3. å›¾åƒé¢„å¤„ç†
        4. åˆ›å»ºæ•°æ®é›†å¯¹è±¡
    """
    print(f"ğŸ“‚ åŠ è½½ {phase} æ•°æ®é›†...")
    
    try:
        # åŠ è½½PICMUSæ•°æ®
        plane_wave_data = load_datasets("simulation", "resolution_distorsion", "iq")
        
        # æ‰§è¡ŒDASé‡å»º
        single_images, multi_images, das, iqdata, xlims, zlims = create_das_reconstructions(
            plane_wave_data, single_angle=[1])
        
        # å›¾åƒé¢„å¤„ç†
        single_images = preprocess_images(single_images)
        multi_images = preprocess_images(multi_images)
        
        # æ•°æ®é›†åˆ’åˆ†
        splits = split_dataset(single_images, multi_images)
        
        # æ ¹æ®phaseè·å–å¯¹åº”æ•°æ®
        if phase in splits:
            input_imgs = splits[phase]['input']
            target_imgs = splits[phase]['target']
        else:
            print(f"âš ï¸  æœªçŸ¥é˜¶æ®µ {phase}ï¼Œä½¿ç”¨è®­ç»ƒæ•°æ®")
            input_imgs = splits['train']['input']
            target_imgs = splits['train']['target']
        
        # åˆ›å»ºæ•°æ®é›†å¯¹è±¡
        dataset = AUGANDataset(input_imgs, target_imgs, phase)
        
        # ä¸ºå…¼å®¹æ€§æ·»åŠ é¢å¤–å±æ€§
        dataset.das = das
        dataset.iqdata = iqdata
        dataset.xlims = xlims
        dataset.zlims = zlims
        
        print(f"âœ… {phase} æ•°æ®é›†åŠ è½½å®Œæˆ")
        return dataset
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        # è¿”å›ç©ºæ•°æ®é›†ä½œä¸ºåå¤‡
        return AUGANDataset([], [], phase)


def save_processed_data(input_images, target_images, save_dir='./data'):
    """
    ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°ç£ç›˜
    
    å‚æ•°:
        input_images: è¾“å…¥å›¾åƒåˆ—è¡¨
        target_images: ç›®æ ‡å›¾åƒåˆ—è¡¨
        save_dir: ä¿å­˜ç›®å½•
    
    åŠŸèƒ½:
        å°†å¤„ç†åçš„æ•°æ®ä¿å­˜ä¸º.matæ–‡ä»¶ï¼ŒåŠ é€Ÿåç»­åŠ è½½
    """
    import os
    
    print("ğŸ’¾ ä¿å­˜å¤„ç†åçš„æ•°æ®...")
    os.makedirs(save_dir, exist_ok=True)
    
    try:
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        input_array = np.array(input_images)
        target_array = np.array(target_images)
        
        # ä¿å­˜ä¸º.matæ–‡ä»¶
        sio.savemat(os.path.join(save_dir, 'train_inputdata.mat'), 
                   {'input_data': input_array})
        sio.savemat(os.path.join(save_dir, 'train_targetdata.mat'), 
                   {'target_data': target_array})
        
        print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {save_dir}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥: {e}")


def main():
    """
    ä¸»å‡½æ•° - ç”¨äºç‹¬ç«‹è¿è¡Œæ•°æ®å¤„ç†
    
    åŠŸèƒ½:
        å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹æ¼”ç¤º
    """
    print("ğŸš€ AUGANæ•°æ®å¤„ç†ç¨‹åºå¯åŠ¨...")
    print("="*50)
    
    try:
        # åŠ è½½PICMUSæ•°æ®
        print("1ï¸âƒ£  åŠ è½½PICMUSæ•°æ®é›†...")
        plane_wave_data = load_datasets("simulation", "resolution_distorsion", "iq")
        
        # æ‰§è¡ŒDASé‡å»º
        print("2ï¸âƒ£  æ‰§è¡ŒDASé‡å»º...")
        single_images, multi_images, das, iqdata, xlims, zlims = create_das_reconstructions(
            plane_wave_data)
        
        # å›¾åƒé¢„å¤„ç†
        print("3ï¸âƒ£  å›¾åƒé¢„å¤„ç†...")
        single_images = preprocess_images(single_images)
        multi_images = preprocess_images(multi_images)
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        print("4ï¸âƒ£  ä¿å­˜æ•°æ®...")
        save_processed_data(single_images, multi_images)
        
        # åˆ›å»ºæ•°æ®é›†ç¤ºä¾‹
        print("5ï¸âƒ£  åˆ›å»ºæ•°æ®é›†...")
        dataset = AUGANDataset(single_images, multi_images, 'train')
        
        print("="*50)
        print("ğŸ‰ æ•°æ®å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š å¤„ç†çš„å›¾åƒå¯¹æ•°é‡: {len(single_images)}")
        print(f"ğŸ“ æ•°æ®ä¿å­˜ä½ç½®: ./data/")
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    """
    ç‹¬ç«‹è¿è¡Œæ•°æ®å¤„ç†è„šæœ¬
    
    ä½¿ç”¨æ–¹æ³•:
        python data_process_annotated.py
    
    åŠŸèƒ½:
        é¢„å¤„ç†PICMUSæ•°æ®é›†ï¼Œç”Ÿæˆè®­ç»ƒæ‰€éœ€çš„å›¾åƒå¯¹
    """
    main()