#!/usr/bin/env python3
"""
AUGAN æµ‹è¯•è„šæœ¬ - è¯¦ç»†æ³¨é‡Šç‰ˆ
test_annotated.py - ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œæ¨ç†å’Œè¯„ä¼°

ä¸»è¦åŠŸèƒ½:
1. åŠ è½½è®­ç»ƒå¥½çš„AUGANæ¨¡å‹
2. å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œæ¨ç†ç”Ÿæˆ
3. è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡
4. ä¿å­˜æµ‹è¯•ç»“æœå’Œå¯è§†åŒ–å›¾åƒ

æµ‹è¯•æµç¨‹:
æ¨¡å‹åŠ è½½ â†’ æ•°æ®å‡†å¤‡ â†’ é€å¼ æ¨ç† â†’ æŒ‡æ ‡è®¡ç®— â†’ ç»“æœä¿å­˜
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import os
import time
import sys
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥AUGANé¡¹ç›®æ¨¡å—
from options.test_options import TestOptions
from models import create_model
from data_process import load_dataset, test_image
from torch.utils.data import DataLoader, Dataset, TensorDataset
from utils.metrics import image_evaluation
from cubdl.example_picmus_torch import load_datasets, create_network, mk_img, dispaly_img


def setup_test_environment():
    """
    è®¾ç½®æµ‹è¯•ç¯å¢ƒ
    
    è¿”å›:
        device: è®¡ç®—è®¾å¤‡
    
    åŠŸèƒ½:
        - æ£€æµ‹GPU/CPUå¯ç”¨æ€§
        - æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯
        - è®¾ç½®æµ‹è¯•æ¨¡å¼
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ¯ æµ‹è¯•è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"ğŸ’¾ GPUå†…å­˜: {gpu_memory:.1f} GB")
    
    return device


def load_test_model(opt):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    
    å‚æ•°:
        opt: æµ‹è¯•é€‰é¡¹é…ç½®
    
    è¿”å›:
        model: åŠ è½½çš„æ¨¡å‹å¯¹è±¡
    
    åŠŸèƒ½:
        1. åˆ›å»ºæ¨¡å‹æ¶æ„
        2. åŠ è½½é¢„è®­ç»ƒæƒé‡
        3. è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    """
    print("ğŸ—ï¸  åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(opt)
    model.setup(opt)
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­dropoutã€batchnormç­‰ï¼‰
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {type(model).__name__}")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: ./checkpoints/{opt.name}/")
    
    return model


def prepare_test_data(opt):
    """
    å‡†å¤‡æµ‹è¯•æ•°æ®
    
    å‚æ•°:
        opt: æµ‹è¯•é€‰é¡¹é…ç½®
    
    è¿”å›:
        img_dataset: æµ‹è¯•æ•°æ®é›†
        dataset_len: æ•°æ®é›†å¤§å°
        das, iqdata, xlims, zlims: PICMUSç›¸å…³æ•°æ®
    
    åŠŸèƒ½:
        1. åŠ è½½PICMUSæµ‹è¯•æ•°æ®
        2. åˆ›å»ºDASç½‘ç»œ
        3. å‡†å¤‡æ•°æ®é›†è¿­ä»£å™¨
    """
    print("ğŸ“¡ å‡†å¤‡æµ‹è¯•æ•°æ®...")
    
    # åŠ è½½PICMUSæ•°æ®é›†
    plane_wave_data = load_datasets("simulation", "resolution_distorsion", "iq")
    das, iqdata, xlims, zlims = create_network(plane_wave_data, [1])
    
    # åŠ è½½æµ‹è¯•æ•°æ®é›†
    print("ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®é›†...")
    img_dataset = load_dataset(opt, opt.phase, 0)
    dataset_len = img_dataset.len
    
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®é›†å¤§å°: {dataset_len} ä¸ªæ ·æœ¬")
    
    return img_dataset, dataset_len, das, iqdata, xlims, zlims


def run_inference(model, img_dataset, dataset_len, opt, xlims, zlims):
    """
    æ‰§è¡Œæ¨¡å‹æ¨ç†
    
    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        img_dataset: æµ‹è¯•æ•°æ®é›†
        dataset_len: æ•°æ®é›†å¤§å°
        opt: æµ‹è¯•é€‰é¡¹
        xlims, zlims: æˆåƒåŒºåŸŸèŒƒå›´
    
    è¿”å›:
        results: æ¨ç†ç»“æœå­—å…¸
    
    åŠŸèƒ½:
        1. é€å¼ å›¾åƒè¿›è¡Œæ¨ç†
        2. æ”¶é›†ç”Ÿæˆç»“æœ
        3. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        4. ä¿å­˜å¯è§†åŒ–ç»“æœ
    """
    print("ğŸ”¬ å¼€å§‹æ¨¡å‹æ¨ç†...")
    
    # åˆå§‹åŒ–ç»“æœå­˜å‚¨
    results = {
        'input_images': [],
        'generated_images': [],
        'target_images': [],
        'metrics': {
            'ssim': [],
            'psnr': [],
            'mse': []
        }
    }
    
    # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
    results_dir = f'./results/{opt.name}'
    os.makedirs(results_dir, exist_ok=True)
    
    # æ¨ç†å¾ªç¯
    inference_start_time = time.time()
    
    # é™åˆ¶æµ‹è¯•æ•°é‡ï¼ˆé¿å…è¿‡é•¿æ—¶é—´ï¼‰
    test_samples = min(dataset_len, opt.num_test)
    print(f"ğŸ§ª å°†æµ‹è¯• {test_samples} ä¸ªæ ·æœ¬")
    
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜
        for i in tqdm(range(test_samples), desc="æ¨ç†è¿›åº¦"):
            try:
                # è·å–æµ‹è¯•æ•°æ®
                data = img_dataset.get_item(i)
                input_img = data['A']
                target_img = data['B']
                
                # è®¾ç½®æ¨¡å‹è¾“å…¥
                model.set_input(data)
                
                # æ‰§è¡Œå‰å‘ä¼ æ’­
                model.test()  # è¿è¡Œæ¨¡å‹æ¨ç†
                
                # è·å–ç”Ÿæˆç»“æœ
                generated_img = model.fake_B
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„ç”¨äºè¯„ä¼°
                input_np = input_img.detach().cpu().numpy()
                generated_np = generated_img.detach().cpu().numpy()
                target_np = target_img.detach().cpu().numpy()
                
                # å­˜å‚¨ç»“æœ
                results['input_images'].append(input_np)
                results['generated_images'].append(generated_np)
                results['target_images'].append(target_np)
                
                # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                metrics = calculate_metrics(generated_img, target_img)
                for key, value in metrics.items():
                    results['metrics'][key].append(value)
                
                # å®šæœŸä¿å­˜å¯è§†åŒ–ç»“æœ
                if i % 10 == 0 or i < 20:  # å‰20å¼ å’Œæ¯10å¼ ä¿å­˜ä¸€æ¬¡
                    save_visualization(input_img, generated_img, target_img,
                                     xlims, zlims, i, opt.name, results_dir)
                
            except Exception as e:
                print(f"âš ï¸  æ ·æœ¬ {i} æ¨ç†å¤±è´¥: {e}")
                continue
    
    inference_time = time.time() - inference_start_time
    print(f"â±ï¸  æ¨ç†å®Œæˆï¼Œç”¨æ—¶: {inference_time:.2f}ç§’")
    print(f"âš¡ å¹³å‡æ¨ç†é€Ÿåº¦: {test_samples/inference_time:.2f} æ ·æœ¬/ç§’")
    
    return results


def calculate_metrics(generated_img, target_img):
    """
    è®¡ç®—å›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡
    
    å‚æ•°:
        generated_img: ç”Ÿæˆå›¾åƒ
        target_img: ç›®æ ‡å›¾åƒ
    
    è¿”å›:
        metrics: è¯„ä¼°æŒ‡æ ‡å­—å…¸
    
    æŒ‡æ ‡è¯´æ˜:
        - SSIM: ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•° [0,1]ï¼Œè¶Šå¤§è¶Šå¥½
        - PSNR: å³°å€¼ä¿¡å™ªæ¯”ï¼Œè¶Šå¤§è¶Šå¥½
        - MSE: å‡æ–¹è¯¯å·®ï¼Œè¶Šå°è¶Šå¥½
    """
    try:
        # ç¡®ä¿å›¾åƒåœ¨CPUä¸Šè¿›è¡Œè®¡ç®—
        gen_cpu = generated_img.detach().cpu()
        tar_cpu = target_img.detach().cpu()
        
        # è®¡ç®—MSE
        mse = torch.mean((gen_cpu - tar_cpu) ** 2).item()
        
        # è®¡ç®—PSNR
        if mse > 0:
            psnr = 20 * torch.log10(torch.tensor(1.0) / torch.sqrt(torch.tensor(mse))).item()
        else:
            psnr = float('inf')
        
        # è®¡ç®—SSIMï¼ˆä½¿ç”¨utilsä¸­çš„SSIMå‡½æ•°ï¼‰
        try:
            from utils.pytorch_ssim import ssim
            ssim_value = ssim(gen_cpu, tar_cpu).item()
        except:
            ssim_value = 0.0  # å¦‚æœSSIMè®¡ç®—å¤±è´¥ï¼Œè®¾ä¸º0
        
        return {
            'ssim': ssim_value,
            'psnr': psnr,
            'mse': mse
        }
    
    except Exception as e:
        print(f"âš ï¸  æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return {'ssim': 0.0, 'psnr': 0.0, 'mse': float('inf')}


def save_visualization(input_img, generated_img, target_img, xlims, zlims, 
                      idx, exp_name, results_dir):
    """
    ä¿å­˜å¯è§†åŒ–ç»“æœ
    
    å‚æ•°:
        input_img: è¾“å…¥å›¾åƒï¼ˆå•è§’åº¦DASï¼‰
        generated_img: ç”Ÿæˆå›¾åƒï¼ˆAUGANè¾“å‡ºï¼‰
        target_img: ç›®æ ‡å›¾åƒï¼ˆå¤šè§’åº¦å¤åˆï¼‰
        xlims, zlims: æˆåƒåŒºåŸŸèŒƒå›´
        idx: å›¾åƒç´¢å¼•
        exp_name: å®éªŒåç§°
        results_dir: ç»“æœä¿å­˜ç›®å½•
    
    åŠŸèƒ½:
        ä½¿ç”¨PICMUSæ ‡å‡†æ˜¾ç¤ºå‡½æ•°ç”Ÿæˆä¸‰å›¾å¯¹æ¯”
    """
    try:
        # è°ƒç”¨åŸæœ‰çš„å¯è§†åŒ–å‡½æ•°
        test_image(input_img, generated_img, target_img, 
                  xlims, zlims, idx, 'test', exp_name)
        
        # å¦å¤–ä¿å­˜åˆ°resultsç›®å½•
        save_path = os.path.join(results_dir, f'result_{idx:03d}.png')
        if os.path.exists(f'./images/{exp_name}/test/{idx}_test.png'):
            import shutil
            shutil.copy(f'./images/{exp_name}/test/{idx}_test.png', save_path)
    
    except Exception as e:
        print(f"âš ï¸  å¯è§†åŒ–ä¿å­˜å¤±è´¥ (æ ·æœ¬ {idx}): {e}")


def print_final_statistics(results):
    """
    æ‰“å°æœ€ç»ˆç»Ÿè®¡ç»“æœ
    
    å‚æ•°:
        results: æ¨ç†ç»“æœå­—å…¸
    
    åŠŸèƒ½:
        è®¡ç®—å¹¶æ˜¾ç¤ºå„ç§è¯„ä¼°æŒ‡æ ‡çš„ç»Ÿè®¡ä¿¡æ¯
    """
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡")
    print("="*50)
    
    metrics = results['metrics']
    
    for metric_name, values in metrics.items():
        if values:  # ç¡®ä¿æœ‰æ•°æ®
            mean_val = np.mean(values)
            std_val = np.std(values)
            min_val = np.min(values)
            max_val = np.max(values)
            
            print(f"{metric_name.upper()}:")
            print(f"  å¹³å‡å€¼: {mean_val:.4f} Â± {std_val:.4f}")
            print(f"  èŒƒå›´: [{min_val:.4f}, {max_val:.4f}]")
            print()
    
    print(f"âœ… æ€»æµ‹è¯•æ ·æœ¬æ•°: {len(results['generated_images'])}")
    print("="*50)


def save_results(results, opt):
    """
    ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶
    
    å‚æ•°:
        results: æ¨ç†ç»“æœ
        opt: æµ‹è¯•é€‰é¡¹
    
    åŠŸèƒ½:
        å°†è¯„ä¼°æŒ‡æ ‡ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼Œä¾¿äºåç»­åˆ†æ
    """
    results_dir = f'./results/{opt.name}'
    os.makedirs(results_dir, exist_ok=True)
    
    # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
    metrics_file = os.path.join(results_dir, 'metrics.txt')
    
    with open(metrics_file, 'w') as f:
        f.write("AUGAN æµ‹è¯•ç»“æœ\n")
        f.write("="*50 + "\n")
        f.write(f"å®éªŒåç§°: {opt.name}\n")
        f.write(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æµ‹è¯•æ ·æœ¬æ•°: {len(results['generated_images'])}\n\n")
        
        for metric_name, values in results['metrics'].items():
            if values:
                mean_val = np.mean(values)
                std_val = np.std(values)
                f.write(f"{metric_name.upper()}: {mean_val:.4f} Â± {std_val:.4f}\n")
    
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {metrics_file}")


def main():
    """
    ä¸»å‡½æ•° - æµ‹è¯•ç¨‹åºå…¥å£
    
    å®Œæ•´æµ‹è¯•æµç¨‹:
    1. åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
    2. è§£ææµ‹è¯•é€‰é¡¹
    3. åŠ è½½æ¨¡å‹å’Œæ•°æ®
    4. æ‰§è¡Œæ¨ç†å’Œè¯„ä¼°
    5. ä¿å­˜ç»“æœå’Œç»Ÿè®¡
    """
    print("ğŸ§ª AUGANæµ‹è¯•ç¨‹åºå¯åŠ¨...")
    print("="*50)
    
    # 1. è®¾ç½®æµ‹è¯•ç¯å¢ƒ
    device = setup_test_environment()
    
    # 2. è§£ææµ‹è¯•é€‰é¡¹
    print("ğŸ“‹ è§£ææµ‹è¯•é…ç½®...")
    opt = TestOptions().parse()
    
    # 3. åŠ è½½æ¨¡å‹
    model = load_test_model(opt)
    
    # 4. å‡†å¤‡æµ‹è¯•æ•°æ®
    img_dataset, dataset_len, das, iqdata, xlims, zlims = prepare_test_data(opt)
    
    # 5. æ‰§è¡Œæ¨ç†
    results = run_inference(model, img_dataset, dataset_len, opt, xlims, zlims)
    
    # 6. æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
    print_final_statistics(results)
    
    # 7. ä¿å­˜ç»“æœ
    save_results(results, opt)
    
    # 8. å®Œæˆæ€»ç»“
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ å¯è§†åŒ–ç»“æœ: ./images/{opt.name}/test/")
    print(f"ğŸ“Š è¯„ä¼°ç»“æœ: ./results/{opt.name}/")
    print("="*50)


if __name__ == '__main__':
    """
    ç¨‹åºå…¥å£ç‚¹
    
    ä½¿ç”¨æ–¹æ³•:
        python test_annotated.py --name experiment_name --model test --netG unet_128
    
    å¸¸ç”¨å‚æ•°:
        --name: å®éªŒåç§°ï¼ˆå¯¹åº”è®­ç»ƒæ—¶çš„åç§°ï¼‰
        --model: æ¨¡å‹ç±»å‹ (test)
        --netG: ç”Ÿæˆå™¨æ¶æ„ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        --num_test: æµ‹è¯•æ ·æœ¬æ•°é‡
        --results_dir: ç»“æœä¿å­˜ç›®å½•
    """
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()